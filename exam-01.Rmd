---
title: "Take Home Exam #1"
author: "Taylor Curyto"
date: "February 24, 2024"
output: html_document
---

```{r}
#| label: setup
#| include: false

# set the echo option to FALSE to see how the document looks with the code suppressed
knitr::opts_chunk$set(echo = TRUE)
```

## Rules

1.  Your solutions must be written up in the R Markdown (Rmd) file called `exam-01.Rmd`.
    This file must include your code and write up for each task.
    Your "submission" will be whatever is in your exam repository at the deadline.
    Commit and push the Rmd and the md outputs of that file.

2.  This exam is open book, open internet, closed other people.
    You may use any online or book based resource you would like, but you must include citations for any code that you use (directly or indirectly).
    You **may not** consult with anyone else about this exam other than the Professor or TA for this course.
    You cannot ask direct questions on the internet, or consult with each other, not even for hypothetical questions.

3.  You have until **[DUE DATE]** to complete this exam and turn it in via your personal Github repo - late work will **not** be accepted.
    Technical difficulties are **not** an excuse for late work - do not wait until the last minute to knit / commit / push.

4.  Each question requires a (brief) narrative as well as a (brief) description of your approach.
    You can use comments in your code, but do not extensively count on these.
    I should be able to suppress **all** the code in your document and still be able to read and make sense of your answers.
    See the first setup code chunk in your Rmd file to experiment with suppressing and revealing your code.

5.  Even if the answer seems obvious from the R output, make sure to state it in your narrative as well.
    For example, if the question is asking what is 2 + 2, and you have the following in your document, you should additionally have a sentence that states "2 + 2 is 4."

``` r
2 + 2
# 4
```

1.  You may only use `tidyverse` and `nycflights13` (and its dependencies) for this assignment. Your solutions may not use any other R packages.

## Academic Integrity Statement

*I, Taylor Curyto, hereby state that I have not communicated with or gained information in any way from my classmates or anyone other than the Professor or TA during this exam, and that all work is my own.*

**A note on sharing / reusing code:** I am well aware that a huge volume of code is available on the web to solve any number of problems.
For this exam you are allowed to make use of any online resources (e.g. StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration).
You are also not allowed to ask a question on an external forum, you can only use answers to questions that have already been answered.
Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.
All communication with classmates is explicitly forbidden.

## Getting help

You are not allowed to post any questions on the public community repo or the public questions channel on Slack.
Any questions about the exam must be asked in person in office hours or on Slack via direct message to the Professor or the TAs.
For quickest response we recommend that you start a direct message with the Professor and all the TAs so that whoever gets to it first can respond to you.

## Grading and feedback

The total points for the questions add up to 90 points.
The remaining 10 points are allocated to code style, commit frequency and messages, overall organization, spelling, grammar, etc.
There is also an extra credit question that is worth 5 points.
You will receive feedback as an issue posted to your repository, and your grade will also be recorded on Sakai.

## Logistics

Answer the questions in the document called `exam-01.Rmd`.
Add your code and narrative in the spaces below each question.
Add code chunks as needed.
Use as many lines as you need, but keep your narrative concise.

Before completing, make sure to supress the code and look over your answers one more time.
If the narrative seems sparse or choppy, edit as needed.
Then, revert back to revealing your code.

Don't forget that you will need to configure your user name and email for Git to be able to push to your repository.

## Packages

In addition to `tidyverse`, you will need the `nycflights13` package for the data.
You will first need to install these packages and then load them.

```{r}

install.packages("tidyverse")
install.packages("nycflights13")

```

```{r}

library(tidyverse)
library(nycflights13)
data(flights)

```

## The data

The `nycflights13` package contains information about all flights that departed from NYC (e.g. EWR, JFK and LGA) in 2013.
The main data is in the `flights` data frame, but there are additional data sets which may help understand what causes delays, specifically:

-   `weather`: hourly meteorological data for each airport
-   `planes`: construction information about each plane
-   `airports`: airport names and locations
-   `airlines`: translation between two letter carrier codes and names

## Questions

1.  **Question 1 (10 points)** - What are the ten most common destinations for flights from NYC airports in 2013?
    Make a table that lists these in descending order of frequency and shows the number of fligts heading to each airport.
    
```{r}

top_dest <- flights %>%
  group_by(dest) %>%
  summarize(count=n()) %>%
  arrange(desc(count)) %>%
  head(10)
  
print(top_dest)

```

***The 10 most common destinations for flights from NYC airports in 2013 are ORD, ATL, LAX, BOS, MCO, CLT, SFO, FLL, MIA, and DCA.***

***First, my approach was to group all the observations based on the destinations of each. Then we needed the summarize function to count the number of each destination and then arranged it in descending order to the 10 highest destination cities. The head function was used to get the highest 10 airport destinations only.***

2.  **Question 2 (10 points)** - Which airlines have the most flights departing from NYC airports in 2013?
    Make a table that lists these in descending order of frequency and shows the number of flights for each airline.
    In your narrative mention the names of the airlines as well.
    *Hint:* You can use the `airlines` dataset to look up the airline name based on `carrier` code.
    
```{r}

flights <- merge(flights, airlines, by="carrier")

top_airlines <- flights %>%
  group_by(name) %>%
  summarize(count=n()) %>%
  arrange(desc(count)) %>% 
  head(10)

  
print(top_airlines)

```
***The airlines that have the most flights departing from NYC airports in 2013 are United, JetBlue, EpressJet, Delta, American, Envoy, US Airways, Endeavor Air, Southwest, and Virgin.***

***First, my approach was to merge the two datasets together based on the carrier variable so the carrier and airline names would match. Then, I decided to group all the observations based on the airline name of each. Then we needed the summarize function to count the number of each airline and then arranged it in descending order to the 10 highest airlines used. The head function was used to get the highest 10 airlines only. I used past assignments to help with this question.*** 

3.  **Question 3 (10 points)** - Consider only flights that have non-missing arrival delay information.
    Your answer should include the name of the carrier in addition to the carrier code and the values asked.

    a\.
    Which carrier had the highest mean arrival delay?

    b\.
    Which carrier had the lowest mean arrival delay?
    
```{r}
flights %>%
    group_by(carrier, name) %>%
    summarise(delay = mean(arr_delay, na.rm = TRUE)) %>%
    arrange(desc(delay)) %>% 
    head(1)
```
***F9, or Frontier Airlines Inc. has the highest mean arrival delay.***

***The approach I took was I grouped by the carrier and name because those are the things included. I then summarized it to find the mean of the delay and arranged it in descending order. I used the head function to get the highest value.***

```{r}
flights %>%
    group_by(carrier, name) %>%
    summarise(delay = mean(arr_delay, na.rm = TRUE)) %>%
    arrange(delay) %>% 
    head(1)
```

***AS, or Alaska Airlines Inc. has the lowest mean arrival delay.***

***The approach I took was I grouped by the carrier and name because those are the things included. I then summarized it to find the mean of the delay and arranged it in ascending order. I used the head function to get the lowest value. I used past assignments to help me with this question.***


4.  **Question 4 (10 points)** - What was the mean temperature at the origin airport on the day with the highest departure delay?
    Your answer should include the name of origin airport, the date with the highest departure delay, and the mean temperature on that day.
    

```{r}
high_dep_delay <- flights %>%
  arrange(desc(dep_delay)) %>%
  slice(1) %>%
  select(origin, year, month, day, dep_delay)

meantemp <- high_dep_delay %>%
  left_join(weather, by = c("origin", "year", "month", "day")) %>%
  summarise(
    origin_airport = first(origin),
    date = paste(first(year), first(month), first(day)),
    mean_temp = mean(temp, na.rm = TRUE)
  )

print(meantemp)
```
***The mean temperature at the origin airport on the day with the highest departure delay was 42.6575.***

***First, I arranged it flights according to dep_delay, and then joined that dataset with the weather dataset. Finally, I summarized the dataset and only used the necessary variable names. I used the textbook for this question.***

5.  **Question 5 (15 points)** - Consider breaking the day into four time intervals: 12:01am-6am, 6:01am-12pm, 12:01pm-6pm, 6:01pm-12am.

    a\.
    Calculate the proportion of flights that are delayed at departure at each of these time intervals.

    b\.
    Comment on how the likelihood of being delayed change throughout the day?
    
```{r}
flights <- flights %>%
  mutate(time_interval = case_when(
    hour >= 0 & hour < 6 ~ "12:01am-6am",
    hour >= 6 & hour < 12 ~ "6:01am-12pm",
    hour >= 12 & hour < 18 ~ "12:01pm-6pm",
    hour >= 18 & hour < 24 ~ "6:01pm-12am"
  ))

proportion_delayed <- flights %>%
  mutate(is_delayed = if_else(dep_delay > 0, 1, 0)) %>% 
  group_by(time_interval) %>%
  summarise(proportion_delayed = mean(is_delayed, na.rm = TRUE))

print(proportion_delayed)
```
***During night time, the delay likelihood almost doubles up to around 50%, while early mornings are less likely to get delayed.***

***I first mutated the hour in flights dataset for when the integer is in a specific span of time, the new created column will put the time frame that hour was located in. I then grouped the variables to be based on these time frames and found the mean of the number of flights delayed within these time frames. I used the textbook for this course and other past assignments done.***

6.  **Question 6 (15 points)** - Find the flight with the longest air time.

```{r}
longest_air_time_flight <- flights %>%
  arrange(desc(air_time)) %>%  
  head(1)  

print(longest_air_time_flight)
```


    a\.
    How long is this flight?
    
  ***13 hours and 35 minutes***

    b\.
    What city did it fly to?

***HNL***

    c\.
    How many seats does the plane that flew this flight have?

```{r}
seats <- planes %>%
  filter(tailnum == longest_air_time_flight$tailnum) %>%
  select(seats)

print(seats)
```
***The plane that flew this flight has 292 seats.***

***I first arranged the flights based on airtime in descending order in order to find the highest airtime plane. Then I used the planes dataset to find the longest airtime flights tailnum and select the corresponding number of seats. The slides from past weeks were used to help.***

7.  **Question 7 (15 pts)** - The `airports` data frame contains information on a large number of primarily American airports.
    These data include location information for these airports in the form of latitude and longitude coordinates.
    In this question we limit our focus to the [Contiguous United States](https://en.wikipedia.org/wiki/Contiguous_United_States).
    Visualize and describe the distribution of the longitudes of airports in the Contiguous United States.
    What does this tell you about the geographical distribution of these airports?
    *Hint:* You will first need to limit your analysis to the Contiguous United States.
    [This Wikipedia article](https://en.wikipedia.org/wiki/List_of_extreme_points_of_the_United_States) can help, but you're welcomed to use other resources as well.
    Make sure to cite whatever resource you use.
    
```{r}
contiguous_us_airports <- airports %>%
  filter(lon >= -125 & lon <= -66)

ggplot(contiguous_us_airports, aes(x = lon)) +
  geom_histogram(binwidth = 1, color = "black", fill = "blue") +
  labs(title = "Distribution of Airport Longitudes in the Contiguous United States",
       x = "Longitude",
       y = "Frequency")
```
***In the wiki article, Washington has the west most point in the contiguous US and is about -125 longitude while Maine is the east most point in the contiguous US and is about -66 longitude. Since Hawaii and Alaska have different longitudes outside of this range, -66 - -125 longitude is the range of the contiguous US.So I filtered out anything out of this longitude range and created a histogram based on the frequency of the longitude.***

***This graph seems somewhat skewed to the left, which means there is a lot more airports on the east coast, probably around New York and east coast area. There are a lot more cities on the east so it makes sense.***

8.  **Question 8 (15 pts)** - Recreate the plot included below using the `flights` data.
    Once you have created the visualization, in no more than one paragraph, describe what you think the point of this visualization might be.
    *Hint:* The visualization uses the variable `arrival`, which is not included in the `flights` data frame.
    You will have to create `arrival` yourself, it is a categorical variable that is equal to `"ontime"` when `arr_delay <= 0` and `"delayed"` when `arr_delay > 0`.

![](img/plot-to-recreate.png)

```{r}
flights %>%
  filter(dest %in% c("PHL", "RDU")) %>%
  filter(month == 12) %>%
  mutate(arrival = case_when(arr_delay <= 0 ~ "ontime", arr_delay > 0 ~ "delayed")) %>%
  filter(!is.na(arrival)) %>%
  ggplot(aes(x = arrival, y = dep_delay, color = dest)) +  
  geom_boxplot() +
  facet_grid(dest ~ origin) + 
  labs(title = "On time performance of NYC flights", subtitle = "December 2013", 
       y = "Departure delay", x = "Arrival", color = "Destination")
```
***I used our textbook as well as past assignments that we have done and the slideshows ou have given us to complete this question. I first filtered this to use only December and only use the two specific destinations. I then mutated this dataset to have a column called arrival and if the delay was longer than 0, it was delayed, otherwise ontime. I then made a plot like the ones we have done in the past, and made sure to name all the axis and titles correctly.***

***The point of this visualization is to focus on 2 destinations from different NYC locations to determine the likelihood of the flight getting delayed. Maybe the point is to determine which destination would be better for a layover for example.***

***Resources: textbook - https://r4ds.hadley.nz/***

**Extra Credit (5 pts)** - Create a visualization that effectively shows if there is a relationship between the average daily departure delay and the average daily temperature for all three New York city airports.
Your answer must be given in a single pipe.
(You should only spend time on this question once you have finished answering the others)